{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invokebrowser(url):\n",
    "    '''\n",
    "    instantiates chrome webdriver and browse given url and return webdriver \n",
    "    '''\n",
    "    driver=webdriver.Chrome(r'C:\\Users\\divakar.kareddy\\Hackathon\\chromedriver_win32\\chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    driver.maximize_window()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closedriver(driver):\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the page data into soup object\n",
    "def soup_website(driver):\n",
    "    '''\n",
    "    input-->webdriver instance\n",
    "    output---> soup of the website invoked by driver'''\n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the options available for player in the dropdown\n",
    "def get_options(soup):\n",
    "    '''\n",
    "    input--->soup object of page\n",
    "    output--->return the options present in the dropdown'''\n",
    "    options=soup.find('select',{'class':'si-selectBox'}).find_all('option')\n",
    "    columns=[options[i].text for i in range(len(options))]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapper(columns,excel):\n",
    "    '''\n",
    "    inputs\n",
    "    columns--->list of options present in the dropdown\n",
    "    #table_columns---> list of class of individual column of the table\n",
    "    output\n",
    "    created a excel sheet at pwd with Top10Players as name.\n",
    "    \n",
    "    '''\n",
    "    table_colums=['sipk-lb-detailBlock sipk-lb-rank','sipk-lb-playerName','sipk-lb-detailBlock sipk-lb-team',\\\n",
    "                  'sipk-lb-detailBlock sipk-lb-matchedPlayed','sipk-lb-detailBlock sipk-lb-raidPoints']\n",
    "    for option in range(1,len(columns)+1):\n",
    "        driver.find_element_by_xpath('//*[@id=\"si_dropdown\"]/option['+str(option)+']').click()\n",
    "        time.sleep(1)\n",
    "        page=BeautifulSoup(driver.page_source)\n",
    "        table=page.find('div',{'class':'si-leadBoard-detail-wrap si-stats-partial-data'})\n",
    "        headers_soup=table.find_all('div',{'class':'si-fullName'})\n",
    "        headings= [headers_soup[i].find('span').text for i in range(len(headers_soup))]\n",
    "        dis={}\n",
    "        #to fetch columns data\n",
    "        for col in range(len(table_colums)):\n",
    "            #fetching top 10\n",
    "            data=[]\n",
    "            if col==2:#To fecth team name\n",
    "                data=[table.find_all('a',{'class':table_colums[col]})[row].attrs['href'].replace('/teams/','')\\\n",
    "                   [:-10].replace('-',' ').rstrip(' ').title() for row in range(10)]\n",
    "            else:\n",
    "                 data=[table.find_all('div',{'class':table_colums[col]})[row].find_all('span')[0].text.strip()\\\n",
    "                                    .replace('.','')for row in range(10)]\n",
    "            dis[headings[col]]=data\n",
    "        page_df=pd.DataFrame(dis)\n",
    "        if option==1:\n",
    "            page_df.to_excel(excel,sheet_name=columns[option-1],engine='xlsxwriter',index=False)\n",
    "        else:\n",
    "            book = load_workbook(excel)\n",
    "            writer = pd.ExcelWriter(excel, engine = 'openpyxl')\n",
    "            writer.book = book\n",
    "            page_df.to_excel(writer, sheet_name = columns[option-1])\n",
    "            writer.save()\n",
    "            writer.close()\n",
    "    del page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.prokabaddi.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=invokebrowser(url)\n",
    "#click on stats link on prokabaddi website\n",
    "driver.find_element_by_link_text('STATS').click()\n",
    "#delay of 2 seconds\n",
    "time.sleep(2)\n",
    "#click on VIEW FULL TABLE\n",
    "driver.find_element_by_link_text('VIEW FULL TABLE').click()\n",
    "time.sleep(2)\n",
    "scrapper(get_options(soup_website(driver)),'Top10Player.xlsx')\n",
    "driver.find_element_by_id('team_Btn').click()\n",
    "time.sleep(1)\n",
    "scrapper(get_options(soup_website(driver)),'TopTeams.xlsx')\n",
    "closedriver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
